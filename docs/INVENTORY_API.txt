================================================================================
API DE CARGA DE INVENTARIO - DOCUMENTACION COMPLETA
================================================================================

RESPUESTAS A TUS PREGUNTAS:

1. ENDPOINT DEL BACKEND
   POST /api/inventory/upload

2. QUE ESPERA EL BACKEND
   JSON (NO multipart/form-data)
   
   El frontend debe procesar el archivo Excel/CSV localmente y enviar JSON:
   
   {
     "products": [
       {
         "name": "Producto",
         "slug": "producto-slug",
         "categoryId": "cat_id",
         "brand": "Marca",
         "shortDescription": "Descripcion corta",
         "longDescription": "Descripcion larga",
         "specs": { "key": "value" },
         "requiresInstallation": false,
         "isActive": true,
         "stock": 10,
         "price": 1000
       }
     ],
     "overwriteExisting": false
   }

3. QUE DEVUELVE EL BACKEND
   {
     "success": true,
     "data": {
       "totalProcessed": 100,
       "successful": 95,
       "failed": 3,
       "skipped": 2,
       "errors": [
         { "index": 5, "name": "Producto", "error": "mensaje de error" }
       ],
       "createdIds": ["id1", "id2", "id3"]
     }
   }

4. FLUJO EXACTO
   Paso 1: Usuario selecciona archivo Excel/CSV en el frontend
   Paso 2: Frontend lee el archivo con libreria SheetJS (xlsx)
   Paso 3: Frontend convierte el Excel a JSON con el formato esperado
   Paso 4: Frontend valida datos basicos (campos requeridos, formatos)
   Paso 5: Frontend envia JSON al backend via POST con token de auth
   Paso 6: Backend valida el token de Firebase Auth
   Paso 7: Backend verifica que el usuario sea admin
   Paso 8: Backend procesa cada producto y lo guarda en Firestore
   Paso 9: Backend devuelve resumen con exitosos, fallidos y errores
   Paso 10: Frontend muestra resultado al usuario con toast o modal

5. AUTENTICACION
   Header requerido:
   Authorization: Bearer <firebase-id-token>
   
   Como obtener el token en el frontend:
   const user = auth.currentUser;
   const token = await user.getIdToken();

6. LOGS DEL BACKEND
   El backend registra informacion sobre cada request del frontend:
   - Origen de la peticion (URL del frontend)
   - User-Agent del navegador
   - Timestamp de la operacion
   - Cantidad de productos procesados
   - Resultados (exitosos, fallidos, omitidos)
   
   Esto permite rastrear y diagnosticar problemas de conexion
   entre el frontend y el backend.

================================================================================
ESPECIFICACIONES TECNICAS
================================================================================

URL COMPLETA:
https://backend-amiweb-5udc-ksr25rpkq.vercel.app/api/inventory/upload

METODO HTTP:
POST

HEADERS REQUERIDOS:
Content-Type: application/json
Authorization: Bearer <token>

AUTENTICACION:
Si, requiere token de Firebase Auth con rol admin

LIMITE DE PRODUCTOS:
Maximo 500 productos por request
Recomendado: 200 productos por lote para rendimiento óptimo

ESTRATEGIA DE LOTES (Frontend optimizado):
- Frontend divide inventarios grandes en lotes de 200
- Frontend deduplica por slug antes de enviar
- Frontend reintenta automáticamente productos con errores transitorios
- Backend clasifica errores como transitorios o permanentes

OPTIMIZACIONES IMPLEMENTADAS:
- Batch Writes: Todas las operaciones se ejecutan en una sola transaccion atomica
- Queries Paralelas: Los slugs se verifican en paralelo (chunks de 10 por limitacion de Firestore)
- Verificacion en Memoria: Se obtienen todos los productos existentes de una vez
- Commit Unico: Todas las escrituras se confirman en una sola operacion
- Reduccion de Latencia: Hasta 100x mas rapido que el procesamiento secuencial
- Generacion Automatica de Slugs Unicos: Si detecta duplicados, agrega sufijo numerico (-1, -2, etc.)

MANEJO DE SLUGS DUPLICADOS:
- El backend detecta slugs duplicados automaticamente
- Si overwriteExisting = false: genera slug unico con sufijo numerico
  Ejemplo: "producto-1" ya existe -> crea "producto-1-1", "producto-1-2", etc.
- Si overwriteExisting = true: actualiza el producto existente con ese slug
- El frontend puede confiar en que todos los productos se procesaran sin error de duplicados

VALIDACIONES:
- name: minimo 2 caracteres, maximo 200
- slug: minimo 2 caracteres, maximo 200, debe ser unico
- categoryId: requerido, debe existir en la coleccion categories de Firestore
- brand: minimo 1 caracter, maximo 100
- shortDescription: minimo 2 caracteres, maximo 500
- longDescription: minimo 2 caracteres, maximo 5000
- stock: numero entero >= 0 (opcional, acepta strings y los convierte)
- price: numero positivo (opcional, acepta strings y los convierte)
- requiresInstallation: boolean (acepta: true/false, "si"/"no", "yes", "1"/"0")
- isActive: boolean (acepta: true/false, "si"/"no", "1"/"0", default: true)

COERCION DE TIPOS (automática):
- stock: "10" -> 10, "10.5" -> 10 (redondea hacia abajo)
- price: "99.99" -> 99.99
- requiresInstallation: "si" -> true, "no" -> false
- isActive: "true" -> true, "false" -> false

CAMPOS DEL PRODUCTO:
- sku: string (opcional)
- name: string (requerido, min 2 chars)
- slug: string (requerido, min 2 chars, unico)
- categoryId: string (requerido)
- brand: string (requerido, min 1 char)
- shortDescription: string (requerido, min 2 chars)
- longDescription: string (requerido, min 2 chars)
- specs: objeto clave-valor (opcional, default {})
- requiresInstallation: boolean (opcional, default false)
- isActive: boolean (opcional, default true)
- stock: number (opcional)
- price: number (opcional)

PARAMETRO OVERWRITE:
overwriteExisting: boolean
- false: omite productos con slug duplicado
- true: actualiza productos existentes con el mismo slug

================================================================================
RESPUESTAS DEL BACKEND
================================================================================

EXITO (201 Created):
{
  "success": true,
  "data": {
    "totalProcessed": 100,
    "successful": 95,
    "failed": 3,
    "skipped": 2,
    "errors": [
      {
        "index": 5,
        "name": "Producto con error",
        "slug": "producto-con-error",
        "error": "Product with this slug already exists",
        "isTransient": false
      },
      {
        "index": 8,
        "name": "Otro producto",
        "slug": "otro-producto",
        "error": "DEADLINE_EXCEEDED",
        "isTransient": true
      }
    ],
    "createdIds": ["prod_abc123", "prod_def456"]
  }
}

NOTAS SOBRE ERRORES:
- isTransient: true = Error temporal (timeout, conexión) - REINTENTAR
- isTransient: false = Error permanente (slug duplicado, validación) - NO REINTENTAR
- slug: Incluido para facilitar identificación y reintento

ERROR 401 (No autenticado):
{
  "success": false,
  "error": "No authorization token provided"
}

ERROR 403 (No autorizado):
{
  "success": false,
  "error": "Admin access required"
}

ERROR 400 (Datos invalidos):
{
  "success": false,
  "error": "Invalid payload: products must contain at least 1 item"
}

ERROR 400 (Validacion fallida - con detalles):
{
  "success": false,
  "error": "Errores de validación encontrados:\nFila 2 (Producto A): name: El nombre debe tener al menos 2 caracteres\nFila 3 (Producto B): slug: El slug debe tener al menos 2 caracteres, categoryId: El categoryId es requerido\n... y 10 errores más."
}

NOTA: Los errores de validacion muestran:
- Numero de fila (coincide con Excel, fila 1 = header)
- Nombre del producto (si existe)
- Campo(s) especifico(s) con error
- Mensaje descriptivo de cada error

ERROR 400 (Limite excedido):
{
  "success": false,
  "error": "Maximum 500 products per batch"
}

ERROR 500 (Error del servidor):
{
  "success": false,
  "error": "Unexpected error"
}

================================================================================
CODIGO FRONTEND - PROCESAR TU EXCEL ESPECIFICO
================================================================================

Instalar dependencia:
npm install xlsx

Codigo TypeScript para TU estructura de Excel:

import * as XLSX from 'xlsx';

interface Product {
  sku?: string;
  name: string;
  slug: string;
  categoryId: string;
  brand: string;
  shortDescription: string;
  longDescription: string;
  specs: Record<string, string>;
  requiresInstallation: boolean;
  isActive: boolean;
  stock?: number;
  price?: number;
}

function generateSlug(text: string): string {
  return text
    .toLowerCase()
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '')
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-+|-+$/g, '');
}

// PASO 1: Obtener mapeo de categorías
async function getCategoryMapping(token: string): Promise<Record<string, string>> {
  const response = await fetch(`${API_URL}/api/categories`, {
    headers: { 'Authorization': `Bearer ${token}` }
  });
  
  if (!response.ok) {
    throw new Error('No se pudieron obtener las categorías');
  }
  
  const result = await response.json();
  const categories = result.data;
  
  // Crear mapeo de nombre a ID
  const mapping: Record<string, string> = {};
  categories.forEach((cat: any) => {
    mapping[cat.name.toUpperCase()] = cat.id;
  });
  
  return mapping;
}

// PASO 2: Procesar tu Excel específico
async function parseYourExcelFile(file: File, categoryMapping: Record<string, string>): Promise<Product[]> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    
    reader.onload = (e) => {
      try {
        const data = e.target?.result;
        const workbook = XLSX.read(data, { type: 'binary' });
        const firstSheet = workbook.Sheets[workbook.SheetNames[0]];
        const jsonData = XLSX.utils.sheet_to_json(firstSheet);
        
        const products: Product[] = jsonData.map((row: any) => {
          const familia = row['Familia']?.toString().toUpperCase() || '';
          const subfamilia = row['Subfamilia']?.toString() || '';
          const codigo = row['Codigo']?.toString() || '';
          const producto = row['Producto']?.toString() || '';
          const stock = row['Saldo stock'] || 0;
          
          // Mapear familia a categoryId
          const categoryId = categoryMapping[familia] || 'CATEGORIA_NO_ENCONTRADA';
          
          // Generar slug desde código o producto
          const slug = generateSlug(codigo || producto);
          
          // Construir specs con todos los campos adicionales
          const specs: Record<string, string> = {};
          if (row['Codigo']) specs['Código'] = row['Codigo'].toString();
          if (row['Familia']) specs['Familia'] = row['Familia'].toString();
          if (row['Subfamilia']) specs['Subfamilia'] = row['Subfamilia'].toString();
          if (row['Unidad']) specs['Unidad'] = row['Unidad'].toString();
          if (row['Unidad de ne Bodega']) specs['Bodega'] = row['Unidad de ne Bodega'].toString();
          if (row['Ubicación']) specs['Ubicación'] = row['Ubicación'].toString();
          if (row['N° Serie']) specs['N° Serie'] = row['N° Serie'].toString();
          if (row['Lote']) specs['Lote'] = row['Lote'].toString();
          if (row['Fecha Vencin']) specs['Fecha Vencimiento'] = row['Fecha Vencin'].toString();
          if (row['Por llegar']) specs['Por llegar'] = row['Por llegar'].toString();
          if (row['Reserva']) specs['Reserva'] = row['Reserva'].toString();
          
          return {
            sku: codigo,
            name: producto,
            slug: slug,
            categoryId: categoryId,
            brand: 'AMILAB', // Valor por defecto - cambiar si tienes el dato
            shortDescription: producto || 'Sin descripción',
            longDescription: `${producto}. Familia: ${familia}, Subfamilia: ${subfamilia}, Código: ${codigo}`,
            specs: specs,
            requiresInstallation: false,
            isActive: true,
            stock: parseInt(stock?.toString()) || 0,
            price: undefined // No disponible en tu Excel
          };
        });
        
        resolve(products);
      } catch (error) {
        reject(error);
      }
    };
    
    reader.onerror = reject;
    reader.readAsBinaryString(file);
  });
}

// PASO 3: Flujo completo adaptado a tu Excel
async function handleYourFileUpload(file: File) {
  try {
    // Obtener token
    const user = auth.currentUser;
    if (!user) {
      throw new Error('Usuario no autenticado');
    }
    const token = await user.getIdToken();
    
    // Obtener mapeo de categorías
    console.log('Obteniendo categorías...');
    const categoryMapping = await getCategoryMapping(token);
    console.log('Mapeo de categorías:', categoryMapping);
    
    // Verificar que existan categorías
    if (Object.keys(categoryMapping).length === 0) {
      throw new Error('No hay categorías disponibles. Crea categorías primero.');
    }
    
    // Procesar archivo
    console.log('Procesando archivo...');
    const products = await parseYourExcelFile(file, categoryMapping);
    console.log(`${products.length} productos procesados`);
    
    // Detectar productos con categorías no encontradas
    const withoutCategory = products.filter(p => p.categoryId === 'CATEGORIA_NO_ENCONTRADA');
    if (withoutCategory.length > 0) {
      const familias = [...new Set(withoutCategory.map(p => p.specs['Familia']))];
      console.warn(`${withoutCategory.length} productos sin categoría. Familias no encontradas:`, familias);
      
      const continuar = confirm(
        `Hay ${withoutCategory.length} productos con categorías no encontradas (${familias.join(', ')}).\n\n` +
        `¿Deseas continuar de todas formas? (Fallarán al validarse)`
      );
      
      if (!continuar) {
        return;
      }
    }
    
    // Deduplicar por slug
    const uniqueProducts = new Map();
    const duplicates: string[] = [];
    
    products.forEach(product => {
      if (uniqueProducts.has(product.slug)) {
        duplicates.push(product.slug);
      } else {
        uniqueProducts.set(product.slug, product);
      }
    });
    
    const finalProducts = Array.from(uniqueProducts.values());
    
    if (duplicates.length > 0) {
      console.warn(`${duplicates.length} duplicados removidos`);
    }
    
    // Dividir en lotes de 200
    const BATCH_SIZE = 200;
    const batches: Product[][] = [];
    
    for (let i = 0; i < finalProducts.length; i += BATCH_SIZE) {
      batches.push(finalProducts.slice(i, i + BATCH_SIZE));
    }
    
    console.log(`Procesando ${batches.length} lotes...`);
    
    // Enviar lotes (reutilizar código de lotes con reintentos anterior)
    // ... código de envío de lotes aquí ...
    
  } catch (error) {
    console.error('Error:', error);
    alert(`Error: ${error.message}`);
  }
}

================================================================================

Instalar dependencia:
npm install xlsx

Codigo TypeScript:

import * as XLSX from 'xlsx';

interface Product {
  name: string;
  slug: string;
  categoryId: string;
  brand: string;
  shortDescription: string;
  longDescription: string;
  specs: Record<string, string>;
  requiresInstallation: boolean;
  isActive: boolean;
  stock?: number;
  price?: number;
}

function generateSlug(text: string): string {
  return text
    .toLowerCase()
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '')
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-+|-+$/g, '');
}

function parseSpecs(specsString: string): Record<string, string> {
  if (!specsString) return {};
  
  const specs: Record<string, string> = {};
  const pairs = specsString.split(';');
  
  pairs.forEach(pair => {
    const [key, value] = pair.split(':');
    if (key && value) {
      specs[key.trim()] = value.trim();
    }
  });
  
  return specs;
}

async function parseExcelFile(file: File): Promise<Product[]> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    
    reader.onload = (e) => {
      try {
        const data = e.target?.result;
        const workbook = XLSX.read(data, { type: 'binary' });
        const firstSheet = workbook.Sheets[workbook.SheetNames[0]];
        const jsonData = XLSX.utils.sheet_to_json(firstSheet);
        
        const products: Product[] = jsonData.map((row: any) => ({
          name: row['Nombre'] || row['name'],
          slug: row['Slug'] || generateSlug(row['Nombre'] || row['name']),
          categoryId: row['Categoria ID'] || row['categoryId'],
          brand: row['Marca'] || row['brand'],
          shortDescription: row['Descripcion Corta'] || row['shortDescription'] || '',
          longDescription: row['Descripcion'] || row['longDescription'] || '',
          specs: parseSpecs(row['Especificaciones'] || ''),
          requiresInstallation: (row['Requiere Instalacion'] || '').toLowerCase() === 'si',
          isActive: true,
          stock: parseInt(row['Stock']) || undefined,
          price: parseFloat(row['Precio']) || undefined
        }));
        
        resolve(products);
      } catch (error) {
        reject(error);
      }
    };
    
    reader.onerror = reject;
    reader.readAsBinaryString(file);
  });
}

================================================================================
CODIGO FRONTEND - ENVIAR AL BACKEND
================================================================================

const API_URL = 'https://backend-amiweb-5udc-ksr25rpkq.vercel.app';

interface UploadResult {
  success: boolean;
  data: {
    totalProcessed: number;
    successful: number;
    failed: number;
    skipped: number;
    errors: Array<{ index: number; name: string; error: string }>;
    createdIds: string[];
  };
}

async function uploadInventory(
  products: Product[], 
  token: string,
  overwrite: boolean = false
): Promise<UploadResult> {
  const response = await fetch(`${API_URL}/api/inventory/upload`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({
      products,
      overwriteExisting: overwrite
    })
  });
  
  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error || 'Error al subir inventario');
  }
  
  return response.json();
}

================================================================================
CODIGO FRONTEND - FLUJO COMPLETO CON LOTES Y REINTENTOS
================================================================================

async function handleFileUpload(file: File) {
  try {
    // Paso 1: Obtener token de autenticacion
    const user = auth.currentUser;
    if (!user) {
      throw new Error('Usuario no autenticado');
    }
    const token = await user.getIdToken();
    
    // Paso 2: Procesar archivo Excel
    console.log('Procesando archivo...');
    let products = await parseExcelFile(file);
    console.log(`${products.length} productos encontrados`);
    
    // Paso 3: Deduplicar por slug
    const uniqueProducts = new Map();
    const duplicates: string[] = [];
    
    products.forEach(product => {
      if (uniqueProducts.has(product.slug)) {
        duplicates.push(product.slug);
      } else {
        uniqueProducts.set(product.slug, product);
      }
    });
    
    products = Array.from(uniqueProducts.values());
    
    if (duplicates.length > 0) {
      console.warn(`${duplicates.length} duplicados removidos:`, duplicates);
    }
    
    // Paso 4: Dividir en lotes de 200
    const BATCH_SIZE = 200;
    const batches: Product[][] = [];
    
    for (let i = 0; i < products.length; i += BATCH_SIZE) {
      batches.push(products.slice(i, i + BATCH_SIZE));
    }
    
    console.log(`Dividido en ${batches.length} lotes de ${BATCH_SIZE}`);
    
    // Paso 5: Procesar cada lote con reintentos
    let totalSuccessful = 0;
    let totalFailed = 0;
    let totalSkipped = 0;
    const allErrors: any[] = [];
    
    for (let batchIndex = 0; batchIndex < batches.length; batchIndex++) {
      const batch = batches[batchIndex];
      console.log(`Procesando lote ${batchIndex + 1}/${batches.length}...`);
      
      // Intento inicial
      let result = await uploadInventory(batch, token, false);
      
      totalSuccessful += result.data.successful;
      totalSkipped += result.data.skipped;
      
      // Paso 6: Reintentar productos con errores transitorios
      const transientErrors = result.data.errors.filter(e => e.isTransient);
      
      if (transientErrors.length > 0) {
        console.log(`Reintentando ${transientErrors.length} productos con errores transitorios...`);
        
        // Esperar 2 segundos antes de reintentar
        await new Promise(resolve => setTimeout(resolve, 2000));
        
        // Extraer productos a reintentar
        const productsToRetry = transientErrors.map(e => batch[e.index]);
        
        try {
          const retryResult = await uploadInventory(productsToRetry, token, false);
          totalSuccessful += retryResult.data.successful;
          totalFailed += retryResult.data.failed;
          totalSkipped += retryResult.data.skipped;
          
          // Solo agregar errores que siguen fallando
          allErrors.push(...retryResult.data.errors);
        } catch (error) {
          console.error('Error en reintento:', error);
          allErrors.push(...transientErrors);
        }
      }
      
      // Agregar errores permanentes (no reintentar)
      const permanentErrors = result.data.errors.filter(e => !e.isTransient);
      allErrors.push(...permanentErrors);
      totalFailed += permanentErrors.length;
      
      // Mostrar progreso
      const progress = ((batchIndex + 1) / batches.length) * 100;
      console.log(`Progreso: ${progress.toFixed(0)}%`);
    }
    
    // Paso 7: Mostrar resultados finales
    console.log('Carga completada!');
    console.log(`Total exitosos: ${totalSuccessful}`);
    console.log(`Total fallidos: ${totalFailed}`);
    console.log(`Total omitidos: ${totalSkipped}`);
    
    if (allErrors.length > 0) {
      console.log('Errores:', allErrors);
    }
    
    alert(`Inventario cargado!\n
Exitosos: ${totalSuccessful}
Fallidos: ${totalFailed}
Omitidos: ${totalSkipped}
Duplicados removidos: ${duplicates.length}`);
    
  } catch (error) {
    console.error('Error:', error);
    alert(`Error: ${error.message}`);
  }
}

// Uso en un componente
function InventoryUploader() {
  const handleChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      handleFileUpload(file);
    }
  };
  
  return (
    <input 
      type="file" 
      accept=".xlsx,.xls,.csv" 
      onChange={handleChange}
    />
  );
}

================================================================================
FORMATO EXCEL RECOMENDADO
================================================================================

El archivo Excel debe tener estas columnas (primera fila = encabezados):

OPCION 1 - ESTRUCTURA COMPLETA:
Columna A: Nombre
Columna B: Slug
Columna C: Categoria ID
Columna D: Marca
Columna E: Descripcion Corta
Columna F: Descripcion
Columna G: Especificaciones
Columna H: Requiere Instalacion
Columna I: Stock
Columna J: Precio

OPCION 2 - ESTRUCTURA DE TU EXCEL ACTUAL (mapeo requerido):
Tu Excel tiene:
- Familia → necesita mapearse a categoryId (requiere lookup de categorias)
- Subfamilia → puede usarse para crear categorias anidadas
- Codigo → puede usarse como sku o para generar slug
- Producto → mapear a name
- Unidad → puede incluirse en specs
- Bodega → puede incluirse en specs o ubicación
- Ubicación → puede incluirse en specs
- N° Serie → puede incluirse en specs
- Lote → puede incluirse en specs
- Fecha Vencin → puede incluirse en specs
- Por llegar → puede sumarse a stock futuro
- Reserva → puede incluirse en specs
- Saldo stock → mapear a stock

CAMPOS FALTANTES EN TU EXCEL (requeridos por el backend):
1. slug: se puede generar automáticamente desde "Codigo" o "Producto"
2. categoryId: debe obtenerse mapeando "Familia" a IDs existentes
3. brand (Marca): REQUERIDO - agregar columna o usar valor por defecto
4. shortDescription: REQUERIDO - agregar columna o generar desde "Producto"
5. longDescription: REQUERIDO - agregar columna o generar desde datos
6. price (Precio): OPCIONAL - agregar si se desea

EJEMPLO DE MAPEO EN FRONTEND:

const mapExcelRowToProduct = (row: any, categoryMapping: Record<string, string>) => {
  return {
    sku: row['Codigo'],
    name: row['Producto'],
    slug: generateSlug(row['Codigo'] || row['Producto']),
    categoryId: categoryMapping[row['Familia']] || 'default-category-id',
    brand: row['Marca'] || 'AMILAB', // Valor por defecto si no existe
    shortDescription: row['Producto'] || 'Sin descripción',
    longDescription: `${row['Producto']}. Familia: ${row['Familia']}, Subfamilia: ${row['Subfamilia']}`,
    specs: {
      'Código': row['Codigo'],
      'Familia': row['Familia'],
      'Subfamilia': row['Subfamilia'],
      'Unidad': row['Unidad'],
      'Bodega': row['Bodega'],
      'Ubicación': row['Ubicación'],
      'N° Serie': row['N° Serie'],
      'Lote': row['Lote'],
      'Fecha Vencimiento': row['Fecha Vencin'],
      'Por llegar': row['Por llegar'],
      'Reserva': row['Reserva']
    },
    requiresInstallation: false,
    isActive: true,
    stock: parseInt(row['Saldo stock']) || 0,
    price: undefined // No disponible en tu Excel
  };
};

PASOS PARA ADAPTAR TU EXCEL:

1. CREAR MAPEO DE CATEGORIAS:
   Antes de cargar productos, necesitas:
   a) Obtener todas las categorías existentes: GET /api/categories
   b) Crear un objeto de mapeo: { "CORE": "cat_123", "LAB": "cat_456" }
   c) Si no existe una categoría, crearla primero

2. AGREGAR COLUMNA "MARCA" (o usar valor por defecto):
   - Opción A: Agregar columna "Marca" en el Excel
   - Opción B: Usar "AMILAB" como valor por defecto en el código

3. GENERAR DESCRIPCIONES:
   - shortDescription: Usar nombre del producto
   - longDescription: Combinar varios campos (familia, subfamilia, código)

4. PROCESAR CAMPOS ADICIONALES COMO SPECS:
   - Todos los campos extra (ubicación, lote, etc.) van en "specs"
   - Esto preserva la información sin cambiar el modelo

EJEMPLO DE DATOS:

Nombre                | Slug                  | Categoria ID | Marca    | ...
Microscopio Digital   | microscopio-digital   | cat_123      | Olympus  | ...
Balanza Analitica     | balanza-analitica     | cat_456      | Mettler  | ...

NOTAS IMPORTANTES:
- Slug: debe ser URL-friendly (sin espacios, caracteres especiales)
- Categoria ID: debe existir previamente en Firestore
- Especificaciones: formato "clave:valor;clave2:valor2"
- Requiere Instalacion: escribir "Si" o "No"
- Stock y Precio: son opcionales, dejar en blanco si no aplica

================================================================================
TESTING CON CURL
================================================================================

curl -X POST https://backend-amiweb-5udc-ksr25rpkq.vercel.app/api/inventory/upload \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer TU_TOKEN_AQUI" \
  -d '{
    "products": [
      {
        "name": "Producto de Prueba",
        "slug": "producto-prueba",
        "categoryId": "ID_DE_CATEGORIA_EXISTENTE",
        "brand": "Marca de Prueba",
        "shortDescription": "Descripcion corta de prueba",
        "longDescription": "Esta es una descripcion larga de prueba",
        "specs": {
          "Peso": "1kg",
          "Color": "Blanco"
        },
        "requiresInstallation": false,
        "isActive": true,
        "stock": 5,
        "price": 10000
      }
    ],
    "overwriteExisting": false
  }'

================================================================================
CONSIDERACIONES IMPORTANTES
================================================================================

1. LIMITE DE PRODUCTOS
   - Maximo 500 productos por request
   - Para inventarios grandes, dividir en multiples requests
   - Implementar logica de paginacion si es necesario

2. TIMEOUT
   - Vercel tiene limite de 10 segundos para plan Hobby
   - Con batch writes optimizado, puede procesar 500 productos en 2-3 segundos
   - RECOMENDACION: Usar lotes de 200 productos para margen de seguridad
   - Frontend optimizado divide automáticamente en lotes de 200
   - El procesamiento anterior (secuencial) podia causar timeout con >50 productos
   - Ahora soporta hasta 500 productos sin problemas de timeout

3. SLUGS DUPLICADOS
   - Por defecto se omiten productos con slug duplicado
   - Usar overwriteExisting: true para actualizar existentes
   - El slug debe ser unico en toda la coleccion

4. CATEGORIAS
   - El categoryId debe existir en Firestore antes de subir productos
   - Validar categorias antes de procesar el archivo
   - Crear endpoint GET /api/categories para obtener IDs validos

5. AUTENTICACION
   - El token expira cada 1 hora
   - Renovar token antes de hacer request si es necesario
   - Manejar errores 401 y solicitar reautenticacion

6. RATE LIMITING
   - No hay rate limiting configurado actualmente
   - Considerar implementar en el futuro
   - Por ahora, ser responsable con la frecuencia de requests

7. VALIDACION EN FRONTEND
   - Validar datos antes de enviar al backend
   - Mostrar errores de validacion al usuario
   - Evitar enviar datos invalidos para no desperdiciar quota

8. MANEJO DE ERRORES
   - El backend devuelve errores detallados por producto
   - Mostrar errores al usuario de forma clara
   - Permitir reintentar solo productos fallidos

9. LOGS Y MONITOREO
   - Todas las peticiones se registran con el origen del frontend
   - Los logs incluyen timestamps, origen, y resultados
   - Consultar logs en Vercel Dashboard para diagnostico
   - Headers importantes: Origin, User-Agent, Authorization

10. ESTRATEGIA DE REINTENTOS (Frontend Optimizado)
   - Frontend reintenta automáticamente errores transitorios
   - Backend clasifica errores como transitorios o permanentes
   - Errores transitorios: timeout, network, DEADLINE_EXCEEDED
   - Errores permanentes: slug duplicado, validación fallida
   - Solo reintentar errores con isTransient: true
   - Lógica recomendada: 1 reintento con backoff de 2-3 segundos

11. TROUBLESHOOTING PARA TU ESTRUCTURA DE EXCEL

PROBLEMA: "categoryId: El categoryId es requerido"
SOLUCIÓN:
- Primero crea las categorías en el sistema (una por cada "Familia")
- Obtén el mapeo GET /api/categories
- Mapea cada "Familia" del Excel a un categoryId existente
- Ejemplo: { "CORE": "cat_abc123", "LAB": "cat_def456" }

PROBLEMA: "brand: La marca es requerida"
SOLUCIÓN:
- Opción A: Agregar columna "Marca" en el Excel
- Opción B: Usar valor por defecto "AMILAB" en el código de mapeo

PROBLEMA: "shortDescription/longDescription requeridas"
SOLUCIÓN:
- Generar automáticamente desde el nombre del producto:
  shortDescription: usar campo "Producto"
  longDescription: combinar "Producto + Familia + Subfamilia + Código"

PROBLEMA: Muchos productos con el mismo slug
SOLUCIÓN:
- El backend ahora genera slugs únicos automáticamente
- Si "producto-123" ya existe, crea "producto-123-1", "producto-123-2", etc.
- No necesitas preocuparte por duplicados en el frontend
- Si quieres actualizar productos existentes, marca "overwriteExisting: true"

RECOMENDACIÓN: Para mejor control, genera slugs únicos en el frontend usando:
  slug = generateSlug(`${codigo}-${producto}`)
Esto evita que el backend tenga que agregar sufijos numéricos.

PROBLEMA: Stock no numérico
SOLUCIÓN:
- El backend ahora convierte strings a números automáticamente
- "10" -> 10, "10.5" -> 10 (redondea)
- Si falla, verifica que "Saldo stock" contenga solo números

CHECKLIST ANTES DE CARGAR:
☐ Crear todas las categorías necesarias (basadas en "Familia")
☐ Obtener mapeo de categorías desde el backend
☐ Verificar que todos los "Codigo" sean únicos o permitir deduplicación
☐ Decidir valor por defecto para "brand" (ej: "AMILAB")
☐ Verificar que "Saldo stock" contenga solo números
☐ Probar con un lote pequeño (10-20 productos) primero

================================================================================
RESUMEN EJECUTIVO
================================================================================

ENDPOINT:
POST https://backend-amiweb-5udc-ksr25rpkq.vercel.app/api/inventory/upload

AUTENTICACION:
Header: Authorization: Bearer <firebase-id-token>
Rol requerido: admin

ENTRADA:
JSON con array de productos (max 500)

SALIDA:
JSON con resumen de procesamiento (exitosos, fallidos, errores)

FLUJO:
1. Usuario selecciona Excel/CSV
2. Frontend procesa archivo localmente y deduplica por slug
3. Frontend divide en lotes de 200 productos
4. Frontend envia cada lote al backend
5. Backend procesa con batch writes optimizado
6. Backend clasifica errores como transitorios o permanentes
7. Frontend reintenta productos con errores transitorios
8. Frontend muestra resultados consolidados con progreso

NOTAS:
- No se usa multipart/form-data
- El procesamiento de Excel es en el frontend
- El backend solo recibe y guarda JSON
- Validacion completa en ambos lados

================================================================================
FIN DE LA DOCUMENTACION
================================================================================
